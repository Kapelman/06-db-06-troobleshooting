# Домашнее задание к занятию "6.6. Troubleshooting"

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести данную операцию:
- напишите список операций, которые вы будете производить для остановки запроса пользователя
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB

Решение:

1. Для поиска долгой операции можно воспользоваться командой db.currentOp()
Например, ниже указанная команда вернет все операции, выполняющиеся более 3 ммнут 

db.currentOp(
   {
     "active" : true,
     "secs_running" : { "$gt" : 180 },
     "ns" : /^db1\./
   }
)

Остановить найденную операцию можно командой db.killOP()

2. Можно включить профилирование, которое будет записывать долгие запросы и далее эти запросы можно оптимизировать.
Например, включить профилирование для запросов более 100 мс
> db.setProfilingLevel(1, 100)

Посмотреть запросы можно командой: 
db.system.profile.find().pretty()

Кроме того, из рекомендаций по производительности:
 - Необходимо, чтобы как MongoDB-индексы, так и MongoDB Working Set(данные/полезная информация) максимально размещались в ОЗУ
 - Использовать XFS-файловую систему вместо Ext4, особенно если используется движок WiredTiger(XFS использует параллельный дисковый ввод/вывод,что значительно улучшает производительность по сравнеию с EXT4)
 - Использовать SSD-диски вместо HDD
 - Проверить/установить лиимты

## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:
- сначала рост отношения записанных значений к истекшим
- Redis блокирует операции записи

Как вы думаете, в чем может быть проблема?
 
Ответ может быть вот в этом разделе:

```
Latency generated by expires
Redis evict expired keys in two ways:

One lazy way expires a key when it is requested by a command, but it is found to be already expired.
One active way expires a few keys every 100 milliseconds.
The active expiring is designed to be adaptive. An expire cycle is started every 100 milliseconds (10 times per second), and will do the following:

Sample ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP keys, evicting all the keys already expired.
If the more than 25% of the keys were found expired, repeat.
```

Вывод дающийся в данном разделе:
```
if the database has many, many keys expiring in the same second, and these make up at least 25% of the current population of keys with an expire set, Redis can block in order to get the percentage of keys already expired below 25%.
```
Так как отношение кол-ва записанных ключей к истекших увеличивается пропорционально репликам, то такое поведение системы нормально, т.к. система старается не допустить использования большого кол-ва памяти для истекших ключей.

## Задача 3

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы,
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения данной проблемы вы можете предложить?

Решение:

Обратимся к докуменитации https://dev.mysql.com/doc/refman/5.7/en/error-lost-connection.html
```
Usually it indicates network connectivity trouble and you should check the condition of your network if this error occurs frequently. If the error message includes “during query,” this is probably the case you are experiencing.

Sometimes the “during query” form happens when millions of rows are being sent as part of one or more queries. If you know that this is happening, you should try increasing net_read_timeout from its default of 30 seconds to 60 seconds or longer, sufficient for the data transfer to complete.

More rarely, it can happen when the client is attempting the initial connection to the server. In this case, if your connect_timeout value is set to only a few seconds, you may be able to resolve the problem by increasing it to ten seconds, perhaps more if you have a very long distance or slow connection. You can determine whether you are experiencing this more uncommon cause by using SHOW GLOBAL STATUS LIKE 'Aborted_connects'. It increases by one for each initial connection attempt that the server aborts. You may see “reading authorization packet” as part of the error message; if so, that also suggests that this is the solution that you need.

If the cause is none of those just described, you may be experiencing a problem with BLOB values that are larger than max_allowed_packet, which can cause this error with some clients. Sometime you may see an ER_NET_PACKET_TOO_LARGE error, and that confirms that you need to increase max_allowed_packet.
```

Четыри причины:
1. Сетевые проблемы. Необходимо проверить доступность сети и возможные проблемы в сети.
2. Тяжелый запрос на миллионы строк, возможно установить иное значение переменной increasing net_read_timeout  с 30 секунд на 60 или более,
3. Длительное начальное подключение (редкий случай). Возможно увеличение переменной connect_timeout с пары секунд до 10, например.
4. Хранение и выборка двоичных данных типа BLOB большего размера чем значение max_allowed_packet.  Можно увеличить значение max_allowed_packet.

## Задача 4


Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объемом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

Как бы вы решили данную проблему?

Решение:

Нашел хорошую статью https://habr.com/ru/company/southbridge/blog/464245/

Причина в недостатке памяти из-за которого система останавливает процесс.

Можно:
1. Добавить физически память
2.  Linux может зарезервировать для процессов больше памяти, чем есть, но не выделять ее по факту, и этим поведением управляет параметр ядра Linux. За это отвечает переменная vm.overcommit_memory. Можно использовать эту переменную.

---

### Как cдавать задание

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
